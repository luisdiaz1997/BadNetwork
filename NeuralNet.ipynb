{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "from minpy.context import cpu, gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Net:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.layers = list()\n",
    "        \n",
    "    def add_layer(self, neurons, activation = 'sigmoid'):\n",
    "        self.layers.append( Layer(neurons, activation = activation))\n",
    "        \n",
    "    def set_input(self, inp):\n",
    "        self.inp = inp\n",
    "        self.train_inp = inp\n",
    "        self.feed_forward()\n",
    "        \n",
    "    def set_output(self, out):\n",
    "        self.out = out\n",
    "        self.train_out = out\n",
    "        \n",
    "        \n",
    "    def feed_forward(self):\n",
    "        self.layers[0].set_input(self.train_inp)\n",
    "        for i in range(1, len(self.layers) ):\n",
    "            (self.layers[i]).set_input(self.layers[i-1].output)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def back_propagation(self, lr):\n",
    "        tensor = list()\n",
    "        tensor.append(self.diff())\n",
    "        for i in reversed(range(0, len(self.layers) - 1)):\n",
    "            \n",
    "            tensor.append(np.multiply(\n",
    "                np.matmul(tensor[-1], np.transpose(self.layers[i+1].weights)),\n",
    "                self.layers[i].d_output\n",
    "                ))\n",
    "        \n",
    "        tensor = tensor[::-1]\n",
    "        for i in range(len(tensor)):\n",
    "            self.layers[i].weights -= lr*np.matmul(np.transpose(self.layers[i].inp), tensor[i])\n",
    "            self.layers[i].bias -= lr*np.matmul(np.transpose(self.layers[i].A), tensor[i])\n",
    "        \n",
    "    def train(self, epochs, lr = 1, batch_size = None):\n",
    "        if batch_size is None:\n",
    "            batch_size = self.inp.shape[0]\n",
    "        partitions = int(self.inp.shape[0]/batch_size)\n",
    "        limits = np.linspace(0, self.inp.shape[0], partitions + 1, dtype= int)\n",
    "        \n",
    "            \n",
    "        for epoch in range(epochs):\n",
    "            print('epoch = ', epoch)\n",
    "            for partition in range(partitions):\n",
    "                \n",
    "                \n",
    "                self.train_inp = self.inp[int(limits[partition]):int(limits[partition + 1])]\n",
    "                self.train_out = self.out[int(limits[partition]):int(limits[partition + 1])]\n",
    "                for j in range(1000):\n",
    "                    self.feed_forward()\n",
    "                    self.back_propagation(lr)\n",
    "            \n",
    "            self.train_inp = self.inp\n",
    "            self.train_out = self.out\n",
    "            self.feed_forward()\n",
    "            \n",
    "            self.cost = np.sum((self.diff()**2))\n",
    "            print(self.cost)\n",
    "            \n",
    "    def diff(self):\n",
    "        return self.layers[-1].output - self.train_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        \n",
    "        return np.where(x < 0, 0, x )\n",
    "    \n",
    "    @staticmethod\n",
    "    def d_sigmoid(x):\n",
    "        a = Layer.sigmoid(x)\n",
    "        return a*(1-a)\n",
    "    \n",
    "    @staticmethod\n",
    "    def d_relu(x):\n",
    "        \n",
    "        return np.where(x<0, 0, 1)\n",
    "    \n",
    "    function = { 'sigmoid': (lambda x: Layer.sigmoid(x)), 'relu': (lambda x: Layer.relu(x))}\n",
    "    \n",
    "    d_function = { 'sigmoid': (lambda x: Layer.d_sigmoid(x)), 'relu': (lambda x: Layer.d_relu(x)) }\n",
    "\n",
    "\n",
    "    def __init__(self, neurons, inp = None, activation = 'sigmoid'):\n",
    "        self.init = False\n",
    "        self.neurons = neurons\n",
    "        self.inp = self.set_input(inp)\n",
    "        self.activation = activation\n",
    "        \n",
    "        \n",
    "    def set_input(self, inp):\n",
    "        if (inp is None):\n",
    "            return None\n",
    "        \n",
    "        if (self.init == False):\n",
    "            self.weights = np.random.rand(inp.shape[1], self.neurons)\n",
    "            print (self.weights)\n",
    "            self.bias = np.random.rand(1, self.neurons)\n",
    "            \n",
    "            self.init = True\n",
    "            \n",
    "        self.inp = inp\n",
    "        self.A = np.ones((inp.shape[0], 1))\n",
    "        self.linear = np.add(\n",
    "                        np.matmul(self.inp, self.weights), \n",
    "                        np.matmul(self.A, self.bias)\n",
    "                        )\n",
    "        self.output = Layer.function[self.activation](self.linear)\n",
    "        self.d_output = Layer.d_function[self.activation](self.linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Neural_Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a.add_layer(8, activation = 'relu')\n",
    "a.add_layer(1, activation = 'sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's make and XNOR  gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.array([[0, 0], [0, 1], [1,0], [1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.array([[1], [0], [0], [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58889288 0.47376254 0.42974153 0.51710492 0.8060513  0.17515864\n",
      "  0.73220198 0.18879887]\n",
      " [0.18107061 0.98931447 0.71781734 0.91544777 0.07144451 0.88069144\n",
      "  0.89127948 0.77244956]]\n",
      "[[0.03530982]\n",
      " [0.28301188]\n",
      " [0.39276928]\n",
      " [0.32421123]\n",
      " [0.73555271]\n",
      " [0.50611345]\n",
      " [0.6732969 ]\n",
      " [0.27859633]]\n"
     ]
    }
   ],
   "source": [
    "a.set_input(inp)\n",
    "a.set_output(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0\n",
      "0.9963036315786136\n",
      "epoch =  1\n",
      "0.9879418622594132\n",
      "epoch =  2\n",
      "0.9736549014694793\n",
      "epoch =  3\n",
      "0.9476677467595016\n",
      "epoch =  4\n",
      "0.9010690525487753\n",
      "epoch =  5\n",
      "0.8243300421344222\n",
      "epoch =  6\n",
      "0.7325667177090589\n",
      "epoch =  7\n",
      "0.6311354488259606\n",
      "epoch =  8\n",
      "0.5286144977062928\n",
      "epoch =  9\n",
      "0.43261754298066907\n"
     ]
    }
   ],
   "source": [
    "a.train(epochs = 10, lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.79208751,  0.60456961,  0.42455054,  0.58953859,  0.48712444,\n",
       "         1.41549622,  0.61832473,  0.19256353],\n",
       "       [ 0.25237951,  1.01867984,  0.69075229,  0.91743683, -0.10212221,\n",
       "         1.41622698,  0.80164346,  0.75624703]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.layers[0].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(a.layers[1].output, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train.reshape(-1, 28*28) / 255.0, x_test.reshape(-1, 28*28) / 255.0\n",
    "y_train = np.transpose(np.array([np.where(y_train == element, 1, 0) for element in np.unique(y_train)]))\n",
    "y_test = np.transpose(np.array([np.where(y_test == element, 1, 0) for element in np.unique(y_test)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22cbb67e978>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8554306  0.01817834 0.80255087 ... 0.01298254 0.33946762 0.32260299]\n",
      " [0.24754352 0.82735689 0.63810578 ... 0.54181062 0.49049085 0.8923982 ]\n",
      " [0.20616849 0.1075222  0.31719937 ... 0.42623588 0.33633214 0.75754921]\n",
      " ...\n",
      " [0.87316252 0.24680865 0.04468423 ... 0.59841681 0.68312849 0.02899333]\n",
      " [0.22556358 0.75836759 0.84071409 ... 0.18099462 0.05642617 0.8972032 ]\n",
      " [0.46424953 0.50116017 0.97124436 ... 0.53323184 0.44233326 0.7414268 ]]\n",
      "epoch =  0\n",
      "[11409.793]\n",
      "epoch =  1\n",
      "[10494.833]\n"
     ]
    }
   ],
   "source": [
    "import minpy.numpy as np\n",
    "from minpy.context import cpu, gpu\n",
    "import time\n",
    "with gpu(0):\n",
    "    model = Neural_Net()\n",
    "    model.add_layer(10, activation = 'sigmoid')\n",
    "    model.set_input(np.array(x_train))\n",
    "    model.set_output(np.array(y_train))\n",
    "    t2 = time.time()\n",
    "    model.train(lr = 1e-5, epochs = 2, batch_size = None)\n",
    "    t3 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39802325 0.4449126  0.96094542 ... 0.98182622 0.40138386 0.25742123]\n",
      " [0.67000866 0.38579929 0.67823219 ... 0.98468189 0.97933294 0.88752439]\n",
      " [0.71458113 0.89763371 0.31099804 ... 0.87920508 0.52658276 0.16994142]\n",
      " ...\n",
      " [0.61983326 0.7223776  0.7621549  ... 0.03037107 0.38009689 0.20837013]\n",
      " [0.9279087  0.20387268 0.44302711 ... 0.05527384 0.24797472 0.76075655]\n",
      " [0.10980709 0.29190936 0.29814861 ... 0.86431775 0.0392903  0.07748252]]\n",
      "epoch =  0\n",
      "11413.97518886999\n",
      "epoch =  1\n",
      "10501.94518629532\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "model = Neural_Net()\n",
    "model.add_layer(10, activation = 'sigmoid')\n",
    "model.set_input(x_train)\n",
    "model.set_output(y_train)\n",
    "t0 = time.time()\n",
    "model.train(lr = 1e-5, epochs = 2, batch_size = None)\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on cpu: 233.396916 s/iter\n",
      "run on gpu: 359.417505 s/iter\n"
     ]
    }
   ],
   "source": [
    "print(\"run on cpu: %.6f s/iter\" % ((t1 - t0)))\n",
    "print(\"run on gpu: %.6f s/iter\" % ((t3 - t2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy = 0.9135333333333333\n"
     ]
    }
   ],
   "source": [
    "model.set_input(x_train)\n",
    "model.set_output(y_train)\n",
    "model.feed_forward()\n",
    "predict = np.argmax(model.layers[-1].output, axis=1)\n",
    "y = np.argmax(y_train, axis=1)\n",
    "accuracy = (y == predict)\n",
    "score = sum(np.where(accuracy == True, 1, 0))/len(y)\n",
    "print('Train Accuracy =', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.9162\n"
     ]
    }
   ],
   "source": [
    "model.set_input(x_test)\n",
    "model.set_output(y_test)\n",
    "model.feed_forward()\n",
    "predict = np.argmax(model.layers[-1].output, axis=1)\n",
    "y = np.argmax(y_test, axis=1)\n",
    "accuracy = (y == predict)\n",
    "score = sum(np.where(accuracy == True, 1, 0))/len(y)\n",
    "print('Test Accuracy =', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
